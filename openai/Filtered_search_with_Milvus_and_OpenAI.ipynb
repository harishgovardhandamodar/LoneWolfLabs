{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtered Search with Milvus and OpenAI\n",
    "### Finding your next movie\n",
    "\n",
    "In this notebook we will be going over generating embeddings of movie descriptions with OpenAI and using those embeddings within Milvus to find relevant movies. To narrow our search results and try something new, we are going to be using filtering to do metadata searches. The dataset in this example is sourced from HuggingFace datasets, and contains a little over 8 thousand movie entries.\n",
    "\n",
    "Lets begin by first downloading the required libraries for this notebook:\n",
    "- `openai` is used for communicating with the OpenAI embedding service\n",
    "- `pymilvus` is used for communicating with the Milvus server\n",
    "- `datasets` is used for downloading the dataset\n",
    "- `tqdm` is used for the progress bars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Using cached openai-1.12.0-py3-none-any.whl.metadata (18 kB)\n",
      "Requirement already satisfied: pymilvus in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (2.2.11)\n",
      "Requirement already satisfied: datasets in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (2.17.1)\n",
      "Requirement already satisfied: tqdm in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (4.66.2)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from openai) (3.7.1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Using cached distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from openai) (0.23.3)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from openai) (2.6.1)\n",
      "Requirement already satisfied: sniffio in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from openai) (4.9.0)\n",
      "Requirement already satisfied: grpcio<=1.53.0,>=1.49.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pymilvus) (1.53.0)\n",
      "Requirement already satisfied: protobuf>=3.20.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pymilvus) (4.25.2)\n",
      "Requirement already satisfied: environs<=9.5.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pymilvus) (9.5.0)\n",
      "Requirement already satisfied: ujson>=2.0.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pymilvus) (5.9.0)\n",
      "Requirement already satisfied: pandas>=1.2.4 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pymilvus) (2.1.4)\n",
      "Requirement already satisfied: numpy!=1.25.0rc1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pymilvus) (1.24.4)\n",
      "Requirement already satisfied: filelock in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (3.13.1)\n",
      "Requirement already satisfied: pyarrow>=12.0.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (14.0.2)\n",
      "Requirement already satisfied: pyarrow-hotfix in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (0.6)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: xxhash in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (3.4.1)\n",
      "Requirement already satisfied: multiprocess in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2023.10.0,>=2023.1.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from fsspec[http]<=2023.10.0,>=2023.1.0->datasets) (2023.10.0)\n",
      "Requirement already satisfied: aiohttp in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: huggingface-hub>=0.19.4 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (0.20.3)\n",
      "Requirement already satisfied: packaging in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from datasets) (6.0.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Requirement already satisfied: marshmallow>=3.0.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from environs<=9.5.0->pymilvus) (3.20.2)\n",
      "Requirement already satisfied: python-dotenv in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from environs<=9.5.0->pymilvus) (1.0.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from aiohttp->datasets) (4.0.3)\n",
      "Requirement already satisfied: certifi in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
      "Requirement already satisfied: httpcore<0.17.0,>=0.15.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (0.16.3)\n",
      "Requirement already satisfied: rfc3986<2,>=1.3 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from rfc3986[idna2008]<2,>=1.3->httpx<1,>=0.23.0->openai) (1.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pandas>=1.2.4->pymilvus) (2023.3)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.16.2 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from pydantic<3,>=1.9.0->openai) (2.16.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from requests>=2.19.0->datasets) (2.2.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from httpcore<0.17.0,>=0.15.0->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: six>=1.5 in /Users/harishdamodar/anaconda3/envs/securitybot/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas>=1.2.4->pymilvus) (1.16.0)\n",
      "Using cached openai-1.12.0-py3-none-any.whl (226 kB)\n",
      "Using cached distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: distro, openai\n",
      "Successfully installed distro-1.9.0 openai-1.12.0\n"
     ]
    }
   ],
   "source": [
    "! pip install openai pymilvus datasets tqdm"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the required packages installed we can get started. Lets begin by launching the Milvus service. The file being run is the `docker-compose.yaml` found in the folder of this file. This command launches a Milvus standalone instance which we will use for this test.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "no configuration file provided: not found\n"
     ]
    }
   ],
   "source": [
    "! docker compose up -d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Milvus running we can setup our global variables:\n",
    "- HOST: The Milvus host address\n",
    "- PORT: The Milvus port number\n",
    "- COLLECTION_NAME: What to name the collection within Milvus\n",
    "- DIMENSION: The dimension of the embeddings\n",
    "- OPENAI_ENGINE: Which embedding model to use\n",
    "- openai.api_key: Your OpenAI account key\n",
    "- INDEX_PARAM: The index settings to use for the collection\n",
    "- QUERY_PARAM: The search parameters to use\n",
    "- BATCH_SIZE: How many movies to embed and insert at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "HOST = 'localhost'\n",
    "PORT = 19530\n",
    "COLLECTION_NAME = 'movie_search'\n",
    "DIMENSION = 1536\n",
    "OPENAI_ENGINE = 'text-embedding-3-small'\n",
    "openai.api_key = 'sk-your_key'\n",
    "\n",
    "INDEX_PARAM = {\n",
    "    'metric_type':'L2',\n",
    "    'index_type':\"HNSW\",\n",
    "    'params':{'M': 8, 'efConstruction': 64}\n",
    "}\n",
    "\n",
    "QUERY_PARAM = {\n",
    "    \"metric_type\": \"L2\",\n",
    "    \"params\": {\"ef\": 64},\n",
    "}\n",
    "\n",
    "BATCH_SIZE = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymilvus import connections, utility, FieldSchema, Collection, CollectionSchema, DataType\n",
    "\n",
    "# Connect to Milvus Database\n",
    "connections.connect(host=HOST, port=PORT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove collection if it already exists\n",
    "if utility.has_collection(COLLECTION_NAME):\n",
    "    utility.drop_collection(COLLECTION_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection which includes the id, title, and embedding.\n",
    "fields = [\n",
    "    FieldSchema(name='id', dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "    FieldSchema(name='title', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='type', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='release_year', dtype=DataType.INT64),\n",
    "    FieldSchema(name='rating', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='description', dtype=DataType.VARCHAR, max_length=64000),\n",
    "    FieldSchema(name='embedding', dtype=DataType.FLOAT_VECTOR, dim=DIMENSION)\n",
    "]\n",
    "schema = CollectionSchema(fields=fields)\n",
    "collection = Collection(name=COLLECTION_NAME, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the index on the collection and load it.\n",
    "collection.create_index(field_name=\"embedding\", index_params=INDEX_PARAM)\n",
    "collection.load()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "With Milvus up and running we can begin grabbing our data. Hugging Face Datasets is a hub that holds many different user datasets, and for this example we are using HuggingLearners's netflix-shows dataset. This dataset contains movies and their metadata pairs for over 8 thousand movies. We are going to embed each description and store it within Milvus along with its title, type, release_year and rating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b781c325bae43f2b5dc2a7cb8fd863e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/2.81k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d6c23b5e7a249c6885dfadd3d3dfa59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading data:   0%|          | 0.00/3.40M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "994f2433ef9b418e95b07b7bc3b16b77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# Download the dataset \n",
    "dataset = datasets.load_dataset('hugginglearners/netflix-shows', split='train')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert the Data\n",
    "Now that we have our data on our machine we can begin embedding it and inserting it into Milvus. The embedding function takes in text and returns the embeddings in a list format. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple function that converts the texts to embeddings\n",
    "def embed(texts):\n",
    "    embeddings = openai.Embedding.create(\n",
    "        input=texts,\n",
    "        engine=OPENAI_ENGINE\n",
    "    )\n",
    "    return [x['embedding'] for x in embeddings['data']]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This next step does the actual inserting. We iterate through all the entries and create batches that we insert once we hit our set batch size. After the loop is over we insert the last remaning batch if it exists. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 999/8807 [00:00<00:01, 4502.31it/s]\n"
     ]
    },
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m data[\u001b[38;5;241m4\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(dataset[i][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m%\u001b[39m BATCH_SIZE \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 19\u001b[0m     data\u001b[38;5;241m.\u001b[39mappend(\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     20\u001b[0m     collection\u001b[38;5;241m.\u001b[39minsert(data)\n\u001b[1;32m     21\u001b[0m     data \u001b[38;5;241m=\u001b[39m [[],[],[],[],[]]\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36membed\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(texts):\n\u001b[0;32m----> 3\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPENAI_ENGINE\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "data = [\n",
    "    [], # title\n",
    "    [], # type\n",
    "    [], # release_year\n",
    "    [], # rating\n",
    "    [], # description\n",
    "]\n",
    "\n",
    "# Embed and insert in batches\n",
    "for i in tqdm(range(0, len(dataset))):\n",
    "    data[0].append(dataset[i]['title'] or '')\n",
    "    data[1].append(dataset[i]['type'] or '')\n",
    "    data[2].append(dataset[i]['release_year'] or -1)\n",
    "    data[3].append(dataset[i]['rating'] or '')\n",
    "    data[4].append(dataset[i]['description'] or '')\n",
    "    if len(data[0]) % BATCH_SIZE == 0:\n",
    "        data.append(embed(data[4]))\n",
    "        collection.insert(data)\n",
    "        data = [[],[],[],[],[]]\n",
    "\n",
    "# Embed and insert the remainder \n",
    "if len(data[0]) != 0:\n",
    "    data.append(embed(data[4]))\n",
    "    collection.insert(data)\n",
    "    data = [[],[],[],[],[]]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Query the Database\n",
    "With our data safely inserted in Milvus, we can now perform a query. The query takes in a tuple of the movie description you are searching for an the filter to use. More info about the filter can be found [here](https://milvus.io/docs/boolean.md). The search first prints out your description and filter expression. After that for each result we print the score, title, type, release year, rating, and description of the result movies. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "APIRemovedInV1",
     "evalue": "\n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 17\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[38;5;28mprint\u001b[39m()\n\u001b[1;32m     15\u001b[0m my_query \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmovie about a fluffly animal\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_year < 2019 and rating like \u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124mPG\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;130;01m\\\"\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mquery\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmy_query\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m, in \u001b[0;36mquery\u001b[0;34m(query, top_k)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mquery\u001b[39m(query, top_k \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m      4\u001b[0m     text, expr \u001b[38;5;241m=\u001b[39m query\n\u001b[0;32m----> 5\u001b[0m     res \u001b[38;5;241m=\u001b[39m collection\u001b[38;5;241m.\u001b[39msearch(\u001b[43membed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m, anns_field\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m, expr \u001b[38;5;241m=\u001b[39m expr, param\u001b[38;5;241m=\u001b[39mQUERY_PARAM, limit \u001b[38;5;241m=\u001b[39m top_k, output_fields\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtitle\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelease_year\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrating\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdescription\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, hit \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(res):\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDescription:\u001b[39m\u001b[38;5;124m'\u001b[39m, text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpression:\u001b[39m\u001b[38;5;124m'\u001b[39m, expr)\n",
      "Cell \u001b[0;32mIn[9], line 3\u001b[0m, in \u001b[0;36membed\u001b[0;34m(texts)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21membed\u001b[39m(texts):\n\u001b[0;32m----> 3\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mopenai\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEmbedding\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtexts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mOPENAI_ENGINE\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [x[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m embeddings[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m~/anaconda3/envs/securitybot/lib/python3.9/site-packages/openai/lib/_old_api.py:39\u001b[0m, in \u001b[0;36mAPIRemovedInV1Proxy.__call__\u001b[0;34m(self, *_args, **_kwargs)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m_args: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m---> 39\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m APIRemovedInV1(symbol\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_symbol)\n",
      "\u001b[0;31mAPIRemovedInV1\u001b[0m: \n\nYou tried to access openai.Embedding, but this is no longer supported in openai>=1.0.0 - see the README at https://github.com/openai/openai-python for the API.\n\nYou can run `openai migrate` to automatically upgrade your codebase to use the 1.0.0 interface. \n\nAlternatively, you can pin your installation to the old version, e.g. `pip install openai==0.28`\n\nA detailed migration guide is available here: https://github.com/openai/openai-python/discussions/742\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "def query(query, top_k = 5):\n",
    "    text, expr = query\n",
    "    res = collection.search(embed(text), anns_field='embedding', expr = expr, param=QUERY_PARAM, limit = top_k, output_fields=['title', 'type', 'release_year', 'rating', 'description'])\n",
    "    for i, hit in enumerate(res):\n",
    "        print('Description:', text, 'Expression:', expr)\n",
    "        print('Results:')\n",
    "        for ii, hits in enumerate(hit):\n",
    "            print('\\t' + 'Rank:', ii + 1, 'Score:', hits.score, 'Title:', hits.entity.get('title'))\n",
    "            print('\\t\\t' + 'Type:', hits.entity.get('type'), 'Release Year:', hits.entity.get('release_year'), 'Rating:', hits.entity.get('rating'))\n",
    "            print(textwrap.fill(hits.entity.get('description'), 88))\n",
    "            print()\n",
    "\n",
    "my_query = ('movie about a fluffly animal', 'release_year < 2019 and rating like \\\"PG%\\\"')\n",
    "\n",
    "query(my_query)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "haystack",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
