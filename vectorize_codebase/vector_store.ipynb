{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c23393bf",
      "metadata": {
        "id": "c23393bf"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/docs/examples/low_level/vector_store.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbbcac09-a0ab-4b7e-9d9b-5b96ac57611d",
      "metadata": {
        "id": "cbbcac09-a0ab-4b7e-9d9b-5b96ac57611d"
      },
      "source": [
        "# Building a (Very Simple) Vector Store from Scratch\n",
        "\n",
        "In this tutorial, we show you how to build a simple in-memory vector store that can store documents along with metadata. It will also expose a query interface that can support a variety of queries:\n",
        "- semantic search (with embedding similarity)\n",
        "- metadata filtering\n",
        "\n",
        "**NOTE**: Obviously this is not supposed to be a replacement for any actual vector store (e.g. Pinecone, Weaviate, Chroma, Qdrant, Milvus, or others within our wide range of vector store integrations). This is more to teach some key retrieval concepts, like top-k embedding search + metadata filtering.\n",
        "\n",
        "We won't be covering advanced query/retrieval concepts such as approximate nearest neighbors, sparse/hybrid search, or any of the system concepts that would be required for building an actual database."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f205323d-2003-4c5e-afa4-64fdda5b8c18",
      "metadata": {
        "id": "f205323d-2003-4c5e-afa4-64fdda5b8c18"
      },
      "source": [
        "## Setup\n",
        "\n",
        "We load in some documents, and parse them into Node objects - chunks that are ready to be inserted into a vector store."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "93871efd-e460-491b-87ef-132109c00244",
      "metadata": {
        "id": "93871efd-e460-491b-87ef-132109c00244"
      },
      "source": [
        "#### Load in Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "c495e86a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c495e86a",
        "outputId": "4ffdcbf4-f6d7-4ec3-b174-eafb8d9244b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: llama-index-readers-file in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (0.1.13)\n",
            "Requirement already satisfied: pymupdf in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (1.24.1)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.3 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-readers-file) (4.12.3)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-readers-file) (0.10.27)\n",
            "Requirement already satisfied: pypdf<5.0.0,>=4.0.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-readers-file) (4.1.0)\n",
            "Requirement already satisfied: striprtf<0.0.27,>=0.0.26 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-readers-file) (0.0.26)\n",
            "Requirement already satisfied: PyMuPDFb==1.24.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pymupdf) (1.24.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->llama-index-readers-file) (2.5)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.9.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.10.0)\n",
            "Requirement already satisfied: httpx in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.26.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.1.16)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.8.1)\n",
            "Requirement already satisfied: numpy in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.12.0)\n",
            "Requirement already satisfied: pandas in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (10.0.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (8.2.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.10.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.14.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.5.3)\n",
            "Requirement already satisfied: anyio in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.7.1)\n",
            "Requirement already satisfied: certifi in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.2)\n",
            "Requirement already satisfied: idna in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.4)\n",
            "Requirement already satisfied: sniffio in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.14.0)\n",
            "Requirement already satisfied: click in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.10.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.26.18)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (3.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2023.3)\n",
            "Requirement already satisfied: exceptiongroup in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.0.4)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (2.14.6)\n",
            "Requirement already satisfied: six>=1.5 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-readers-file) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n",
            "Requirement already satisfied: llama-index-embeddings-openai in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (0.1.7)\n",
            "Requirement already satisfied: llama-index-core<0.11.0,>=0.10.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-embeddings-openai) (0.10.27)\n",
            "Requirement already satisfied: PyYAML>=6.0.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy>=1.4.49 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.9.0)\n",
            "Requirement already satisfied: dataclasses-json in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.8)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.10.0)\n",
            "Requirement already satisfied: httpx in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.26.0)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.16 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.1.16)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.6.0)\n",
            "Requirement already satisfied: networkx>=3.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.1)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.8.1)\n",
            "Requirement already satisfied: numpy in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.26.4)\n",
            "Requirement already satisfied: openai>=1.1.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.12.0)\n",
            "Requirement already satisfied: pandas in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.1.4)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (10.0.1)\n",
            "Requirement already satisfied: requests>=2.31.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.2.2)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.66.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.10.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.9.0)\n",
            "Requirement already satisfied: wrapt in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.14.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.6->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (4.0.3)\n",
            "Requirement already satisfied: pydantic>=1.10 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.5.3)\n",
            "Requirement already satisfied: anyio in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.11.17)\n",
            "Requirement already satisfied: httpcore==1.* in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.2)\n",
            "Requirement already satisfied: idna in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.4)\n",
            "Requirement already satisfied: sniffio in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.0)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from httpcore==1.*->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.14.0)\n",
            "Requirement already satisfied: click in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (8.1.7)\n",
            "Requirement already satisfied: joblib in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from nltk<4.0.0,>=3.8.1->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.10.3)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from openai>=1.1.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from requests>=2.31.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.26.18)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from typing-inspect>=0.8.0->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (3.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2023.3)\n",
            "Requirement already satisfied: exceptiongroup in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from anyio->httpx->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.0.4)\n",
            "Requirement already satisfied: packaging>=17.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (23.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.14.6 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from pydantic>=1.10->llamaindex-py-client<0.2.0,>=0.1.16->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (2.14.6)\n",
            "Requirement already satisfied: six>=1.5 in /Users/harishdamodar/anaconda3/envs/dl/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->llama-index-core<0.11.0,>=0.10.1->llama-index-embeddings-openai) (1.16.0)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install llama-index-readers-file pymupdf\n",
        "%pip install llama-index-embeddings-openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "694e4a15-3736-47f6-b323-59b6c6492fad",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "694e4a15-3736-47f6-b323-59b6c6492fad",
        "outputId": "0b76e79e-7a3b-40c3-dbbc-778937f7fb55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "mkdir: data: File exists\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2024-04-05 11:53:17--  https://arxiv.org/pdf/2305.05959.pdf\n",
            "Resolving arxiv.org (arxiv.org)... 151.101.195.42, 151.101.131.42, 151.101.3.42, ...\n",
            "Connecting to arxiv.org (arxiv.org)|151.101.195.42|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1730915 (1,7M) [application/pdf]\n",
            "Saving to: ‘data/llama2.pdf’\n",
            "\n",
            "data/llama2.pdf     100%[===================>]   1,65M   873KB/s    in 1,9s    \n",
            "\n",
            "2024-04-05 11:53:19 (873 KB/s) - ‘data/llama2.pdf’ saved [1730915/1730915]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!mkdir data\n",
        "!wget --user-agent \"Mozilla\" \"https://arxiv.org/pdf/2305.05959.pdf\" -O \"data/llama2.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e1f99ca0-aea9-4441-bace-c66d797a88db",
      "metadata": {
        "id": "e1f99ca0-aea9-4441-bace-c66d797a88db"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "from llama_index.readers.file import PyMuPDFReader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "da320f97-b332-44cb-a0c6-7b5eb7cabaf1",
      "metadata": {
        "id": "da320f97-b332-44cb-a0c6-7b5eb7cabaf1"
      },
      "outputs": [],
      "source": [
        "loader = PyMuPDFReader()\n",
        "documents = loader.load(file_path=\"./data/llama2.pdf\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f8cf70c0-1b67-4855-b2e2-e28fd235f8b7",
      "metadata": {
        "id": "f8cf70c0-1b67-4855-b2e2-e28fd235f8b7"
      },
      "source": [
        "#### Parse into Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "6ee31469-024c-44a0-bd40-bb038e422575",
      "metadata": {
        "id": "6ee31469-024c-44a0-bd40-bb038e422575"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "\n",
        "node_parser = SentenceSplitter(chunk_size=256)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7641b59e-1ce4-4168-84fa-db98048e940f",
      "metadata": {
        "id": "7641b59e-1ce4-4168-84fa-db98048e940f"
      },
      "source": [
        "#### Generate Embeddings for each Node"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "7803b109-98e6-460a-b209-9442660318a9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 525
        },
        "id": "7803b109-98e6-460a-b209-9442660318a9",
        "outputId": "ecd00250-c01a-42ef-eed8-5be3a82a2cc1"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying llama_index.embeddings.openai.base.get_embedding in 0.7980201722261249 seconds as it raised APIConnectionError: Connection error..\n"
          ]
        }
      ],
      "source": [
        "from llama_index.embeddings.openai import OpenAIEmbedding\n",
        "\n",
        "embed_model = OpenAIEmbedding()\n",
        "for node in nodes:\n",
        "    node_embedding = embed_model.get_text_embedding(\n",
        "        node.get_content(metadata_mode=\"all\")\n",
        "    )\n",
        "    node.embedding = node_embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe942484-a399-4044-9c9f-ea175f9dbafe",
      "metadata": {
        "id": "fe942484-a399-4044-9c9f-ea175f9dbafe"
      },
      "source": [
        "## Build a Simple In-Memory Vector Store\n",
        "\n",
        "Now we'll build our in-memory vector store. We'll store Nodes within a simple Python dictionary. We'll start off implementing embedding search, and add metadata filters."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "808f4f0b-0a1f-4f90-b0f1-c08693998189",
      "metadata": {
        "id": "808f4f0b-0a1f-4f90-b0f1-c08693998189"
      },
      "source": [
        "### 1. Defining the Interface\n",
        "\n",
        "We'll first define the interface for building a vector store. It contains the following items:\n",
        "\n",
        "- `get`\n",
        "- `add`\n",
        "- `delete`\n",
        "- `query`\n",
        "- `persist` (which we will not implement)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71c21211-54c4-4493-bf50-548f99b36f65",
      "metadata": {
        "id": "71c21211-54c4-4493-bf50-548f99b36f65"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.vector_stores.types import VectorStore\n",
        "from llama_index.core.vector_stores import (\n",
        "    VectorStoreQuery,\n",
        "    VectorStoreQueryResult,\n",
        ")\n",
        "from typing import List, Any, Optional, Dict\n",
        "from llama_index.core.schema import TextNode, BaseNode\n",
        "import os\n",
        "\n",
        "\n",
        "class BaseVectorStore(VectorStore):\n",
        "    \"\"\"Simple custom Vector Store.\n",
        "\n",
        "    Stores documents in a simple in-memory dict.\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    stores_text: bool = True\n",
        "\n",
        "    def get(self, text_id: str) -> List[float]:\n",
        "        \"\"\"Get embedding.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def add(\n",
        "        self,\n",
        "        nodes: List[BaseNode],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Add nodes to index.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def delete(self, ref_doc_id: str, **delete_kwargs: Any) -> None:\n",
        "        \"\"\"\n",
        "        Delete nodes using with ref_doc_id.\n",
        "\n",
        "        Args:\n",
        "            ref_doc_id (str): The doc_id of the document to delete.\n",
        "\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "    def query(\n",
        "        self,\n",
        "        query: VectorStoreQuery,\n",
        "        **kwargs: Any,\n",
        "    ) -> VectorStoreQueryResult:\n",
        "        \"\"\"Get nodes for response.\"\"\"\n",
        "        pass\n",
        "\n",
        "    def persist(self, persist_path, fs=None) -> None:\n",
        "        \"\"\"Persist the SimpleVectorStore to a directory.\n",
        "\n",
        "        NOTE: we are not implementing this for now.\n",
        "\n",
        "        \"\"\"\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "73d291ef-78f7-4cee-a9e3-ee9b6b557354",
      "metadata": {
        "id": "73d291ef-78f7-4cee-a9e3-ee9b6b557354"
      },
      "source": [
        "At a high-level, we subclass our base `VectorStore` abstraction. There's no inherent reason to do this if you're just building a vector store from scratch. We do it because it makes it easy to plug into our downstream abstractions later.\n",
        "\n",
        "Let's look at some of the classes defined here.\n",
        "- `BaseNode` is simply the parent class of our core Node modules. Each Node represents a text chunk + associated metadata.\n",
        "- We also use some lower-level constructs, for instance our `VectorStoreQuery` and `VectorStoreQueryResult`. These are just lightweight dataclass containers to represent queries and results. We look at the dataclass fields below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f1de927f-fb4c-48d9-a26c-2d9bfc453e36",
      "metadata": {
        "id": "f1de927f-fb4c-48d9-a26c-2d9bfc453e36"
      },
      "outputs": [],
      "source": [
        "from dataclasses import fields\n",
        "\n",
        "{f.name: f.type for f in fields(VectorStoreQuery)}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e9fe73ed-ade8-4a67-ba0b-1cb195bb78ab",
      "metadata": {
        "id": "e9fe73ed-ade8-4a67-ba0b-1cb195bb78ab"
      },
      "outputs": [],
      "source": [
        "{f.name: f.type for f in fields(VectorStoreQueryResult)}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b94a1410-3b98-40ad-be3d-1bb79762b723",
      "metadata": {
        "id": "b94a1410-3b98-40ad-be3d-1bb79762b723"
      },
      "source": [
        "### 2. Defining `add`, `get`, and `delete`\n",
        "\n",
        "We add some basic capabilities to add, get, and delete from a vector store.\n",
        "\n",
        "The implementation is very simple (everything is just stored in a python dictionary)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "590a3112-4bfe-4378-89d9-f10dbd41ef02",
      "metadata": {
        "id": "590a3112-4bfe-4378-89d9-f10dbd41ef02"
      },
      "outputs": [],
      "source": [
        "class VectorStore2(BaseVectorStore):\n",
        "    \"\"\"VectorStore2 (add/get/delete implemented).\"\"\"\n",
        "\n",
        "    stores_text: bool = True\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        \"\"\"Init params.\"\"\"\n",
        "        self.node_dict: Dict[str, BaseNode] = {}\n",
        "\n",
        "    def get(self, text_id: str) -> List[float]:\n",
        "        \"\"\"Get embedding.\"\"\"\n",
        "        return self.node_dict[text_id]\n",
        "\n",
        "    def add(\n",
        "        self,\n",
        "        nodes: List[BaseNode],\n",
        "    ) -> List[str]:\n",
        "        \"\"\"Add nodes to index.\"\"\"\n",
        "        for node in nodes:\n",
        "            self.node_dict[node.node_id] = node\n",
        "\n",
        "    def delete(self, node_id: str, **delete_kwargs: Any) -> None:\n",
        "        \"\"\"\n",
        "        Delete nodes using with node_id.\n",
        "\n",
        "        Args:\n",
        "            node_id: str\n",
        "\n",
        "        \"\"\"\n",
        "        del self.node_dict[node_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c31a321a-b14f-4819-a26a-25b41401905d",
      "metadata": {
        "id": "c31a321a-b14f-4819-a26a-25b41401905d"
      },
      "source": [
        "We run some basic tests just to show it works well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a1729f-a51c-48b7-a82c-88081c16df83",
      "metadata": {
        "id": "91a1729f-a51c-48b7-a82c-88081c16df83"
      },
      "outputs": [],
      "source": [
        "test_node = TextNode(id_=\"id1\", text=\"hello world\")\n",
        "test_node2 = TextNode(id_=\"id2\", text=\"foo bar\")\n",
        "test_nodes = [test_node, test_node2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4044322-d104-47ef-b44f-440ca0ef5441",
      "metadata": {
        "id": "f4044322-d104-47ef-b44f-440ca0ef5441"
      },
      "outputs": [],
      "source": [
        "vector_store = VectorStore2()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0650d3b2-0df0-4f6d-be61-6c4cc81d1479",
      "metadata": {
        "id": "0650d3b2-0df0-4f6d-be61-6c4cc81d1479"
      },
      "outputs": [],
      "source": [
        "vector_store.add(test_nodes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d8973354-43c1-4e2d-8209-683501361ea2",
      "metadata": {
        "id": "d8973354-43c1-4e2d-8209-683501361ea2"
      },
      "outputs": [],
      "source": [
        "node = vector_store.get(\"id1\")\n",
        "print(str(node))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "aaeff1d2-a609-4b64-bc4d-9c491b189c51",
      "metadata": {
        "id": "aaeff1d2-a609-4b64-bc4d-9c491b189c51"
      },
      "source": [
        "### 3.a Defining `query` (semantic search)\n",
        "\n",
        "We implement a basic version of top-k semantic search. This simply iterates through all document embeddings, and compute cosine-similarity with the query embedding. The top-k documents by cosine similarity are returned.\n",
        "\n",
        "Cosine similarity: $\\dfrac{\\vec{d}\\vec{q}}{|\\vec{d}||\\vec{q}|}$ for every document, query embedding pair $\\vec{d}$, $\\vec{p}$.\n",
        "\n",
        "**NOTE**: The top-k value is contained in the `VectorStoreQuery` container.\n",
        "\n",
        "**NOTE**: Similar to the above, we define another subclass just so we don't have to reimplement the above functions (not because this is actually good code practice)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4c3902ca-9463-4920-8d64-36a5ce0a3dcf",
      "metadata": {
        "id": "4c3902ca-9463-4920-8d64-36a5ce0a3dcf"
      },
      "outputs": [],
      "source": [
        "from typing import Tuple\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_top_k_embeddings(\n",
        "    query_embedding: List[float],\n",
        "    doc_embeddings: List[List[float]],\n",
        "    doc_ids: List[str],\n",
        "    similarity_top_k: int = 5,\n",
        ") -> Tuple[List[float], List]:\n",
        "    \"\"\"Get top nodes by similarity to the query.\"\"\"\n",
        "    # dimensions: D\n",
        "    qembed_np = np.array(query_embedding)\n",
        "    # dimensions: N x D\n",
        "    dembed_np = np.array(doc_embeddings)\n",
        "    # dimensions: N\n",
        "    dproduct_arr = np.dot(dembed_np, qembed_np)\n",
        "    # dimensions: N\n",
        "    norm_arr = np.linalg.norm(qembed_np) * np.linalg.norm(\n",
        "        dembed_np, axis=1, keepdims=False\n",
        "    )\n",
        "    # dimensions: N\n",
        "    cos_sim_arr = dproduct_arr / norm_arr\n",
        "\n",
        "    # now we have the N cosine similarities for each document\n",
        "    # sort by top k cosine similarity, and return ids\n",
        "    tups = [(cos_sim_arr[i], doc_ids[i]) for i in range(len(doc_ids))]\n",
        "    sorted_tups = sorted(tups, key=lambda t: t[0], reverse=True)\n",
        "\n",
        "    sorted_tups = sorted_tups[:similarity_top_k]\n",
        "\n",
        "    result_similarities = [s for s, _ in sorted_tups]\n",
        "    result_ids = [n for _, n in sorted_tups]\n",
        "    return result_similarities, result_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c6e325ec-6108-4747-b0e7-00ee248d5ff7",
      "metadata": {
        "id": "c6e325ec-6108-4747-b0e7-00ee248d5ff7"
      },
      "outputs": [],
      "source": [
        "class VectorStore3A(VectorStore2):\n",
        "    \"\"\"Implements semantic/dense search.\"\"\"\n",
        "\n",
        "    def query(\n",
        "        self,\n",
        "        query: VectorStoreQuery,\n",
        "        **kwargs: Any,\n",
        "    ) -> VectorStoreQueryResult:\n",
        "        \"\"\"Get nodes for response.\"\"\"\n",
        "\n",
        "        query_embedding = cast(List[float], query.query_embedding)\n",
        "        doc_embeddings = [n.embedding for n in self.node_dict.values()]\n",
        "        doc_ids = [n.node_id for n in self.node_dict.values()]\n",
        "\n",
        "        similarities, node_ids = get_top_k_embeddings(\n",
        "            query_embedding,\n",
        "            embeddings,\n",
        "            doc_ids,\n",
        "            similarity_top_k=query.similarity_top_k,\n",
        "        )\n",
        "        result_nodes = [self.node_dict[node_id] for node_id in node_ids]\n",
        "\n",
        "        return VectorStoreQueryResult(\n",
        "            nodes=result_nodes, similarities=similarities, ids=node_ids\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4ca6994-06d1-49b9-b1f9-e4bd9bcbe2f9",
      "metadata": {
        "id": "c4ca6994-06d1-49b9-b1f9-e4bd9bcbe2f9"
      },
      "source": [
        "### 3.b. Supporting Metadata Filtering\n",
        "\n",
        "The next extension is adding metadata filter support. This means that we will first filter the candidate set with documents that pass the metadata filters, and then perform semantic querying.\n",
        "\n",
        "For simplicity we use metadata filters for exact matching with an AND condition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "57637533-efaf-43cd-bff2-cae428d6e507",
      "metadata": {
        "id": "57637533-efaf-43cd-bff2-cae428d6e507"
      },
      "outputs": [],
      "source": [
        "from llama_index.core.vector_stores import MetadataFilters\n",
        "from llama_index.core.schema import BaseNode\n",
        "from typing import cast\n",
        "\n",
        "\n",
        "def filter_nodes(nodes: List[BaseNode], filters: MetadataFilters):\n",
        "    filtered_nodes = []\n",
        "    for node in nodes:\n",
        "        matches = True\n",
        "        for f in filters.filters:\n",
        "            if f.key not in node.metadata:\n",
        "                matches = False\n",
        "                continue\n",
        "            if f.value != node.metadata[f.key]:\n",
        "                matches = False\n",
        "                continue\n",
        "        if matches:\n",
        "            filtered_nodes.append(node)\n",
        "    return filtered_nodes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c48feeb4-c6da-42c6-a2c8-aab407ddf652",
      "metadata": {
        "id": "c48feeb4-c6da-42c6-a2c8-aab407ddf652"
      },
      "source": [
        "We add `filter_nodes` as a first-pass over the nodes before running semantic search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "77a0418c-fa51-423a-a04d-d5c3990713e0",
      "metadata": {
        "id": "77a0418c-fa51-423a-a04d-d5c3990713e0"
      },
      "outputs": [],
      "source": [
        "def dense_search(query: VectorStoreQuery, nodes: List[BaseNode]):\n",
        "    \"\"\"Dense search.\"\"\"\n",
        "    query_embedding = cast(List[float], query.query_embedding)\n",
        "    doc_embeddings = [n.embedding for n in nodes]\n",
        "    doc_ids = [n.node_id for n in nodes]\n",
        "    return get_top_k_embeddings(\n",
        "        query_embedding,\n",
        "        doc_embeddings,\n",
        "        doc_ids,\n",
        "        similarity_top_k=query.similarity_top_k,\n",
        "    )\n",
        "\n",
        "\n",
        "class VectorStore3B(VectorStore2):\n",
        "    \"\"\"Implements Metadata Filtering.\"\"\"\n",
        "\n",
        "    def query(\n",
        "        self,\n",
        "        query: VectorStoreQuery,\n",
        "        **kwargs: Any,\n",
        "    ) -> VectorStoreQueryResult:\n",
        "        \"\"\"Get nodes for response.\"\"\"\n",
        "        # 1. First filter by metadata\n",
        "        nodes = self.node_dict.values()\n",
        "        if query.filters is not None:\n",
        "            nodes = filter_nodes(nodes, query.filters)\n",
        "        if len(nodes) == 0:\n",
        "            result_nodes = []\n",
        "            similarities = []\n",
        "            node_ids = []\n",
        "        else:\n",
        "            # 2. Then perform semantic search\n",
        "            similarities, node_ids = dense_search(query, nodes)\n",
        "            result_nodes = [self.node_dict[node_id] for node_id in node_ids]\n",
        "        return VectorStoreQueryResult(\n",
        "            nodes=result_nodes, similarities=similarities, ids=node_ids\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c632b32e-abf1-46a6-83bd-2f0d71bfacea",
      "metadata": {
        "id": "c632b32e-abf1-46a6-83bd-2f0d71bfacea"
      },
      "source": [
        "### 4. Load Data into our Vector Store\n",
        "\n",
        "Let's load our text chunks into the vector store, and run it on different types of queries: dense search, w/ metadata filters, and more."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3bffb6ca-824f-4ed0-acda-2d4230cb990f",
      "metadata": {
        "id": "3bffb6ca-824f-4ed0-acda-2d4230cb990f"
      },
      "outputs": [],
      "source": [
        "vector_store = VectorStore3B()\n",
        "# load data into the vector stores\n",
        "vector_store.add(nodes)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "454cb5ae-342b-43c1-9e13-27968971077d",
      "metadata": {
        "id": "454cb5ae-342b-43c1-9e13-27968971077d"
      },
      "source": [
        "Define an example question and embed it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cd8f3f42-9f7e-493f-812a-fc1f91464da9",
      "metadata": {
        "id": "cd8f3f42-9f7e-493f-812a-fc1f91464da9"
      },
      "outputs": [],
      "source": [
        "query_str = \"Can you tell me about the key concepts for safety finetuning\"\n",
        "query_embedding = embed_model.get_query_embedding(query_str)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0e8ffd63-6b7d-4722-b05e-1d8045114821",
      "metadata": {
        "id": "0e8ffd63-6b7d-4722-b05e-1d8045114821"
      },
      "source": [
        "#### Query the vector store with dense search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c46802a8-2de8-45bf-bd45-384e73d6ae57",
      "metadata": {
        "id": "c46802a8-2de8-45bf-bd45-384e73d6ae57"
      },
      "outputs": [],
      "source": [
        "query_obj = VectorStoreQuery(\n",
        "    query_embedding=query_embedding, similarity_top_k=2\n",
        ")\n",
        "\n",
        "query_result = vector_store.query(query_obj)\n",
        "for similarity, node in zip(query_result.similarities, query_result.nodes):\n",
        "    print(\n",
        "        \"\\n----------------\\n\"\n",
        "        f\"[Node ID {node.node_id}] Similarity: {similarity}\\n\\n\"\n",
        "        f\"{node.get_content(metadata_mode='all')}\"\n",
        "        \"\\n----------------\\n\\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bbb40f1a-b414-44b8-b16d-7942f57d3975",
      "metadata": {
        "id": "bbb40f1a-b414-44b8-b16d-7942f57d3975"
      },
      "source": [
        "#### Query the vector store with dense search + Metadata Filters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2b02e55-39a0-4cfa-b14a-f35346e77364",
      "metadata": {
        "id": "f2b02e55-39a0-4cfa-b14a-f35346e77364"
      },
      "outputs": [],
      "source": [
        "# filters = MetadataFilters(\n",
        "#     filters=[\n",
        "#         ExactMatchFilter(key=\"page\", value=3)\n",
        "#     ]\n",
        "# )\n",
        "filters = MetadataFilters.from_dict({\"source\": \"24\"})\n",
        "\n",
        "query_obj = VectorStoreQuery(\n",
        "    query_embedding=query_embedding, similarity_top_k=2, filters=filters\n",
        ")\n",
        "\n",
        "query_result = vector_store.query(query_obj)\n",
        "for similarity, node in zip(query_result.similarities, query_result.nodes):\n",
        "    print(\n",
        "        \"\\n----------------\\n\"\n",
        "        f\"[Node ID {node.node_id}] Similarity: {similarity}\\n\\n\"\n",
        "        f\"{node.get_content(metadata_mode='all')}\"\n",
        "        \"\\n----------------\\n\\n\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97df839d-379e-4d19-a760-00998cf0e482",
      "metadata": {
        "id": "97df839d-379e-4d19-a760-00998cf0e482"
      },
      "source": [
        "## Build a RAG System with the Vector Store\n",
        "\n",
        "Now that we've built the RAG system, it's time to plug it into our downstream system!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fdd6b6b3-9942-464d-ba3b-6b5ddf6aedd8",
      "metadata": {
        "id": "fdd6b6b3-9942-464d-ba3b-6b5ddf6aedd8"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import VectorStoreIndex"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e3354341-be69-43f0-8496-76fc32dad64e",
      "metadata": {
        "id": "e3354341-be69-43f0-8496-76fc32dad64e"
      },
      "outputs": [],
      "source": [
        "index = VectorStoreIndex.from_vector_store(vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1619f80b-e407-42e0-9efe-46dcc80e8624",
      "metadata": {
        "id": "1619f80b-e407-42e0-9efe-46dcc80e8624"
      },
      "outputs": [],
      "source": [
        "query_engine = index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "13443687-d779-4542-a795-552b42cdf116",
      "metadata": {
        "id": "13443687-d779-4542-a795-552b42cdf116"
      },
      "outputs": [],
      "source": [
        "query_str = \"How to evaluate a code search model?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c0e7b03-65b4-4b16-923a-0f059388e4de",
      "metadata": {
        "id": "1c0e7b03-65b4-4b16-923a-0f059388e4de"
      },
      "outputs": [],
      "source": [
        "response = query_engine.query(query_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e0dd1457-732e-456c-9075-19ea256a63fb",
      "metadata": {
        "id": "e0dd1457-732e-456c-9075-19ea256a63fb"
      },
      "outputs": [],
      "source": [
        "print(str(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fe8647e5-2338-4a50-835e-a31e32118a5a",
      "metadata": {
        "id": "fe8647e5-2338-4a50-835e-a31e32118a5a"
      },
      "source": [
        "## Conclusion\n",
        "\n",
        "That's it! We've built a simple in-memory vector store that supports very simple inserts, gets, deletes, and supports dense search and metadata filtering. This can then be plugged into the rest of LlamaIndex abstractions.\n",
        "\n",
        "It doesn't support sparse search yet and is obviously not meant to be used in any sort of actual app. But this should expose some of what's going on under the hood!"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "dl",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
